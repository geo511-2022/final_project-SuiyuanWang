---
title: "Mapping fine-scale population using dasymetric method"
author: Suiyuan Wang
subtitle: A case study in Buffalo city, NY
---

# Introduction

Knowledge of the fine-level population distribution is vital for measuring the impacts of socio-economic justice, optimizing resource allocation, and assessing the risks of environmental exposures. The traditional way to get population data is from the census bureau. However, population data released by the census bureau are too coarse and irregular to satisfy the requirements of accurate analysis. To solve the irregular shape and too coarse level problem of census data, we would downscale the census block group level data to census block. As for the method, the dasymetric method would be applied. The dasymetric method uses locality knowledge to depict the uneven population distribution within zones without assuming even distributions. This volume preserve method disaggregates the population within the source zone to the target zones according to the weighted layer generated by population-related ancillary information to preserve the total population count. The dasymetric method has been evaluated as a practical and feasible way for population disaggregation. Finally, the result will be evaluated by comparing it with census block data. This project aims to apply the dasymetric method to disaggregate census data to get fine-level population data using open-source data.

# Materials and methods

## Load request packages for this project.
```{r, message=F, warning=F}
library(sf)
library(leaflet)
library(piggyback)
library(tmap) 
library(lwgeom)
knitr::opts_chunk$set(cache=TRUE)  # cache the results for quick compiling
```

## Data preprocessing
### Download data 

```{r}
dataurl = "https://github.com/geo511-2022/final_project-SuiyuanWang/releases/download/v1.0.4/Data_GEO511_project.zip"

#tdir=tempdir()
#download.file(dataurl,destfile=file.path(tdir,"temp.zip"))
#unzip(file.path(tdir,"temp.zip"),exdir = tdir) #unzip the compressed folder

download.file(dataurl,"temp.zip")
unzip("temp.zip") #unzip the compressed folder
```
```{r, echo=FALSE}
dasymetric_map <- function(target, source, ancillary_data, tid = NULL, extensive = NULL) {

  # Add IDs
  if(missing(tid)){
    target[['AW_tid']] <- 1:nrow(target)
    tid <- 'AW_tid'
  }
  source[['AW_sid']] <- 1:nrow(source)

  # Intersect Source to Intermediate
  first_int <- sf::st_intersection(source, ancillary_data)

  # Generate ID for Intersection
  first_int['AW_fid'] <- 1:nrow(first_int)

  # Compute Area for First Interpolation
  first_int['AW_area'] <- sf::st_area(first_int)

  # Calculate Area as a Proportion of Source Area
  cov_area <- first_int |>
    sf::st_drop_geometry() |>
    dplyr::group_by(.data$AW_sid) |>
    dplyr::summarise(AW_cov_area = sum(.data$AW_area))

  first_int <- dplyr::left_join(first_int, cov_area, by = 'AW_sid')
  first_int['AW_area_prp'] <- as.numeric(first_int$AW_area / first_int$AW_cov_area)

  # Multiply Extensive Variables by this Proportion
  for(i in extensive){
    first_int[[i]] <- first_int[[i]] * first_int[['AW_area_prp']]
  }

  # Intersect Again, Intermediate to Target
  target_int <- sf::st_intersection(first_int, target)

  # Calculate New Area (And Ratio)
  target_int['AW_t_area'] <- sf::st_area(target_int)
  target_int['AW_t_prp'] <- as.numeric(target_int[['AW_t_area']] / target_int[['AW_area']])

  # Multiply Extensive Again
  for(i in extensive){
    target_int[[i]] <- target_int[[i]] * target_int[['AW_t_prp']]
  }

  # Group And Summarise Extensive
  summary <- target_int |>
    sf::st_drop_geometry() |>
    dplyr::group_by(!!dplyr::sym(tid)) |>
    dplyr::summarise_at(extensive, sum)

  # Join To Target
  target <- dplyr::left_join(target, summary, by = tid)

  return(target)
}
```

### Load data.
* Buffalo zoning data.
* Census boundaries (2020) with population. 
 * Census block population_block
 * Census block group population_bg
* Microsoft building footprint (2018).
```{r}
#landuse <- st_read("Data_GEO511_project/zoning.shp") 
source_geom <- st_read("Data_GEO511_project/census_bg.shp")
target_geom <- st_read("Data_GEO511_project/census_block.shp")
residential_bf <- st_read("Data_GEO511_project/residential_bf.shp")
#st_crs(residential_bf)
#st_crs(target_geom)
#st_crs(source_geom)
#st_crs(landuse)
```

### Clean required data

For building footprint data, we first filter the data using zoning data that has residential property. Then, make the source data, target data and ancillary data have the consistent crs.
Find [zoning codes](https://data.buffalony.gov/Economic-Neighborhood-Development/Zoning/5843-jknb) related to residential:
```{r, warning=FALSE, message=FALSE}
### Residential zonings.The provided 'residential_bf.shp' already after filter using ArcGIS pro.
#residential_code = c('N-2R', 'N-3R', 'N-4-30', 'N-4-50', 'D-R')
#residential <- landuse %>% filter(gcode == residential_code) 
#residential_wgs84  <- residential %>%  st_transform(4326) 

# set projection for geometries.
target_geom_wgs84  <- target_geom %>%  st_transform(4326) 
source_geom_wgs84  <- source_geom %>%  st_transform(4326) 
```

### Disaggregate population 

The data was downscaled from the source zone (census block group) to the target zone (census block) using building footprint areas in the target zone as ancillary data. After downscaling, we would convert data as an integer and` NA` as 0, due to the population number can only be an integer and larger than or equal to zero.
```{r dasymetric, warning=FALSE, message=FALSE}
# dasymetric map with building footprint information as ancillary data
sf_use_s2(FALSE)

dm_pop = dasymetric_map(target_geom_wgs84, source_geom_wgs84, residential_bf, extensive = "population")

# convert estimation result to integer, and replace NA as 0.
dm_pop[is.na(dm_pop)] <- 0 
dm_pop$population = as.integer(dm_pop$population)
```

# Results

Evaluating the result by plotting ground truth data and estimation results. Then, calculate R2 and coefficients.
[Refer To](https://lukemiller.org/index.php/2012/10/adding-p-values-and-r-squared-values-to-a-plot-using-expression/)

```{r}
#calculate r2 in dm_pop, 'population'(estimate) & 'Population'(ground truth)
mod1 = lm(Population~population, data = dm_pop)
modsum = summary(mod1)
plot(dm_pop$Population, dm_pop$population, type = 'p', las = 1,
		xlab = expression(paste('Census block Population')),
		ylab = 'Estimate population')

#adding the regression line from the linear model
abline(mod1)
```

```{r}
r2 = modsum$adj.r.squared
print(paste("R2 = ", r2))
```

```{r}
modsum$coefficients
```

We are using `tmap` to show the ground truth and estimation result in an interactive map. By exploring the map, we can easily find the outlier's location and discuss the reason.

```{r}
tm_shape(dm_pop) +
  tm_fill(col = c("population", "Population"), 
          style = "jenks", 
          title = c("Estimate_Population", "True_Population")) + 
  tm_facets(ncol = 2, sync = TRUE) +
  tmap_mode("view")
```

# Conclusions

This project aims to apply the dasymetric method to disaggregate census data to get fine-level population data using open-source data.
The results show that R2 for this research is 0.62. We can see the potential by only using building footprint as ancillary data to downscaling population. It shows that population distribution has a high correlation with residential building distribution.
However, there do have some outliers. The blocks that have a high population tend to be underestimated, and low-population blocks tend to be overestimated. We find the errors are caused by the following reasons: 
* Inherent error in zoning data. The building classification used zoning data. The buildings in zoning that didn't have residential property will be weighted as 0, and not input into the dasymetric function for final estimation. So, if the block doesnâ€™t have residential zoning, it will be allocated 0 population. 
* Blocks have other residential usage units. The other reason is that the block has mixing usage buildings, like commercial and residential mixing buildings cannot be identified. 
* Buildings have many floors. The building footprint can only know the one-floor area of the buildings. However, a high population density area always has high buildings to occupy more population.
For the problems mentioned above, we can try to use more accurate data as ancillary data to weight the population distribution. The zoning data can be crossed verification or replaced using more specific data like tax parcels. As for high buildings, we can first use LiDAR data to find the building height and then use average floor height to get the floor number for buildings. As for the mixing usages of buildings, after we know the building height, we can use points of interest from Google or OpenStreetMap to calculate the percentage of commercial floors in one building.
 

# References

1. Bakillah, M., et al. (2014). "Fine-resolution population mapping using OpenStreetMap points-of-interest." International Journal of Geographical Information Science 28(9): 1940-1963.
2. Frantz, D., et al. (2021). "National-scale mapping of building height using Sentinel-1 and Sentinel-2 time series." Remote Sensing of Environment 252: 112128.
3. Huang, X., et al. (2021). "A 100 m population grid in the CONUS by disaggregating census data with open-source Microsoft building footprints." Big earth data 5(1): 112-133.
4. Huang, X., et al. (2019). High-resolution population grid in the CONUS using microsoft building footprints: A feasibility study. Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Geospatial Humanities.
5. Maantay, J. A., et al. (2007). "Mapping population distribution in the urban environment: The cadastral-based expert dasymetric system (CEDS)." Cartography and Geographic Information Science 34(2): 77-102.
6. Mennis, J. (2009). "Dasymetric mapping for estimating population in small areas." Geography Compass 3(2): 727-745.
7. Mennis, J. and T. Hultgren (2006). "Intelligent dasymetric mapping and its application to areal interpolation." Cartography and Geographic Information Science 33(3): 179-194.
8. Qiu, Y., et al. (2022). "Disaggregating population data for assessing progress of SDGs: methods and applications."  15(1): 2-29.


